{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "selected_folders = 'images_001|images_002|images_003|images_004|images_005'\n",
    "\n",
    "# Load and filter data\n",
    "data = pd.read_csv('./data/Data_Entry_2017.csv')\n",
    "data = data[data['Patient Age'] < 100]  # Removing invalid ages\n",
    "data_image_paths = {os.path.basename(x): x for x in glob(os.path.join('.', 'data', 'images*', '*', '*.png'))}\n",
    "data['path'] = data['Image Index'].map(data_image_paths.get)\n",
    "data['Patient Age'] = data['Patient Age'].astype(int)\n",
    "data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\n",
    "mask = data['path'].str.contains(selected_folders)\n",
    "data = data[mask]\n",
    "\n",
    "\n",
    "# Process labels\n",
    "from itertools import chain\n",
    "all_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\n",
    "all_labels = [x for x in all_labels if x]\n",
    "for label in all_labels:\n",
    "    if len(label) > 1:  # Avoid empty labels\n",
    "        data[label] = data['Finding Labels'].map(lambda findings: 1.0 if label in findings else 0)\n",
    "\n",
    "# Filter labels to keep\n",
    "MIN_CASES = 1000\n",
    "all_labels = [label for label in all_labels if data[label].sum() > MIN_CASES]\n",
    "data['disease_vec'] = data[all_labels].values.tolist()\n",
    "\n",
    "# Print information\n",
    "print(f\"Clean Labels ({len(all_labels)}): {[(label, int(data[label].sum())) for label in all_labels]}\")\n",
    "print('Scans found:', len(data_image_paths), ', Total Headers:', data.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChestXrayDataset(Dataset):\n",
    "    def __init__(self, dataframe, image_paths, labels, transform=None):\n",
    "        self.dataframe = dataframe\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.dataframe.iloc[idx]['path']\n",
    "        image = Image.open(image_path).convert('RGB')\n",
    "        label = torch.tensor(self.dataframe.iloc[idx][self.labels].astype(float).values)\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Define transforms\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Split data\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_df, test_df = train_test_split(data, test_size=0.20, random_state=2018, stratify=data['Finding Labels'].str[:4])\n",
    "train_df, valid_df = train_test_split(train_df, test_size=0.10, random_state=2018, stratify=train_df['Finding Labels'].str[:4])\n",
    "\n",
    "train_dataset = ChestXrayDataset(train_df, data_image_paths, all_labels, transform=transform)\n",
    "valid_dataset = ChestXrayDataset(valid_df, data_image_paths, all_labels, transform=transform)\n",
    "test_dataset = ChestXrayDataset(test_df, data_image_paths, all_labels, transform=transform)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision.models import googlenet\n",
    "from torchvision.models import vgg16\n",
    "\n",
    "class GoogleNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GoogleNetModel, self).__init__()\n",
    "        self.model = googlenet(pretrained=True)\n",
    "        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "    \n",
    "class VGGModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(VGGModel, self).__init__()\n",
    "        self.model = vgg16(pretrained=True)\n",
    "        self.model.classifier[-1] = nn.Linear(self.model.classifier[-1].in_features, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        x = self.sigmoid(x)\n",
    "        return x\n",
    "\n",
    "class GoogleVGG(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(GoogleVGG, self).__init__()\n",
    "        self.googlenet = googlenet(pretrained=True)\n",
    "        self.vgg16 = vgg16(pretrained=True)\n",
    "\n",
    "        self.googlenet.fc = nn.Linear(self.googlenet.fc.in_features, num_classes)\n",
    "        self.vgg16.classifier[-1] = nn.Linear(self.vgg16.classifier[-1].in_features, num_classes)\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(num_classes * 2, num_classes),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(num_classes, num_classes),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        output_googlenet = self.googlenet(x)\n",
    "        output_vgg16 = self.vgg16(x)\n",
    "        \n",
    "        combined_features = torch.cat((output_googlenet, output_vgg16), dim=1)\n",
    "        \n",
    "        output = self.sigmoid(self.classifier(combined_features))\n",
    "        return output\n",
    "\n",
    "\n",
    "vgg_model = VGGModel(len(all_labels))\n",
    "vgg_optimizer = optim.Adam(vgg_model.parameters(), lr=0.00001)\n",
    "print(vgg_model)\n",
    "    \n",
    "google_model = GoogleNetModel(len(all_labels))\n",
    "google_optimizer = optim.Adam(google_model.parameters(), lr=0.00001)\n",
    "criterion = nn.BCELoss()\n",
    "print(google_model)\n",
    "\n",
    "model = GoogleVGG(len(all_labels))\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.00001)\n",
    "criterion = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "# Training and Validation Loop\n",
    "def train_and_validate(model, train_loader, valid_loader, criterion, optimizer, num_epochs=20):\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    for epoch in range(num_epochs):\n",
    "        # Training Phase\n",
    "        model.train()\n",
    "        total_train_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        for images, labels in tqdm(train_loader):\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            optimizer.zero_grad()\n",
    "#             print(images.shape)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs.float(), labels.float())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_train_loss += loss.item()\n",
    "            \n",
    "            predicted = (outputs > 0.5).float()\n",
    "            # Count correct predictions\n",
    "            correct = (predicted == labels).all(dim=1).sum().item()\n",
    "            total_correct += correct\n",
    "\n",
    "            # Increment total number of samples\n",
    "            total_samples += labels.size(0)\n",
    "        \n",
    "        avg_train_loss = total_train_loss / len(train_loader)\n",
    "        train_loss.append(avg_train_loss)\n",
    "        train_accuracy = total_correct / total_samples * 100\n",
    "        \n",
    "        # Validation Phase\n",
    "        model.eval()\n",
    "        total_valid_loss = 0.0\n",
    "        total_correct = 0\n",
    "        total_samples = 0\n",
    "        with torch.no_grad():\n",
    "            for images, labels in tqdm(valid_loader):\n",
    "                images, labels = images.cuda(), labels.cuda()\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs.float(), labels.float())\n",
    "                total_valid_loss += loss.item()\n",
    "                \n",
    "                predicted = (outputs > 0.5).float()\n",
    "                # Count correct predictions\n",
    "                correct = (predicted == labels).all(dim=1).sum().item()\n",
    "                total_correct += correct\n",
    "\n",
    "                # Increment total number of samples\n",
    "                total_samples += labels.size(0)\n",
    "\n",
    "        avg_valid_loss = total_valid_loss / len(valid_loader)\n",
    "        val_loss.append(avg_valid_loss)\n",
    "        val_accuracy = total_correct / total_samples * 100\n",
    "        \n",
    "        \n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], '\n",
    "              f'Train Loss: {avg_train_loss:.4f}, '\n",
    "              f'Validation Loss: {avg_valid_loss:.4f}')\n",
    "        print(train_accuracy, val_accuracy)\n",
    "        \n",
    "    return train_loss, val_loss\n",
    "\n",
    "# Continue with model training\n",
    "train_and_validate(model.cuda(), train_loader, valid_loader, criterion, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tqdm import tqdm \n",
    "\n",
    "# def train_and_validate(model, train_loader, valid_loader, criterion, optimizer, num_epochs=20):\n",
    "#     model.to(device, dtype=torch.float32) \n",
    "\n",
    "#     for epoch in range(num_epochs):\n",
    "#         model.train()\n",
    "#         total_train_loss, total_valid_loss = 0, 0\n",
    "#         total_train_correct, total_valid_correct = 0, 0\n",
    "#         total_train_samples, total_valid_samples = 0, 0\n",
    "\n",
    "#         # Training\n",
    "#         for images, labels in tqdm(train_loader):\n",
    "#             images = images.to(device, dtype=torch.float32)\n",
    "#             labels = labels.to(device, dtype=torch.float32)\n",
    "#             optimizer.zero_grad()\n",
    "#             outputs = model(images)\n",
    "#             loss = criterion(outputs, labels)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             total_train_loss += loss.item()\n",
    "\n",
    "#             predicted = outputs.round()\n",
    "#             total_train_correct += (predicted == labels).all(dim=1).sum().item()\n",
    "#             total_train_samples += labels.size(0)\n",
    "\n",
    "#         # Validation\n",
    "#         model.eval()\n",
    "#         with torch.no_grad():\n",
    "#             for images, labels in tqdm(valid_loader):\n",
    "#                 images = images.to(device, dtype=torch.float32)\n",
    "#                 labels = labels.to(device, dtype=torch.float32)\n",
    "#                 outputs = model(images)\n",
    "#                 loss = criterion(outputs, labels)\n",
    "#                 total_valid_loss += loss.item()\n",
    "\n",
    "#                 predicted = outputs.round()\n",
    "#                 total_valid_correct += (predicted == labels).all(dim=1).sum().item()\n",
    "#                 total_valid_samples += labels.size(0)\n",
    "\n",
    "#         avg_train_loss = total_train_loss / len(train_loader)\n",
    "#         avg_valid_loss = total_valid_loss / len(valid_loader)\n",
    "#         train_accuracy = (total_train_correct / total_train_samples) * 100\n",
    "#         valid_accuracy = (total_valid_correct / total_valid_samples) * 100\n",
    "\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}]: Train Loss: {avg_train_loss:.4f}, Validation Loss: {avg_valid_loss:.4f}', flush = True)\n",
    "#         print(f'Train Accuracy: {train_accuracy:.2f}%, Validation Accuracy: {valid_accuracy:.2f}%', flush = True)\n",
    "\n",
    "# # Call training/validation function\n",
    "# # train_and_validate(model, train_loader, valid_loader, criterion, optimizer)\n",
    "# train_and_validate(google_model, train_loader, valid_loader, criterion, google_optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# # Function to compute the ROC AUC score\n",
    "# def compute_roc_auc(model, data_loader, num_classes):\n",
    "#     model.eval()\n",
    "#     y_true = torch.FloatTensor()\n",
    "#     y_pred = torch.FloatTensor()\n",
    "    \n",
    "#     with torch.no_grad():\n",
    "#         for images, labels in tqdm(data_loader):\n",
    "#             outputs = model(images)\n",
    "#             y_true = torch.cat((y_true, labels), 0)\n",
    "#             y_pred = torch.cat((y_pred, outputs), 0)\n",
    "\n",
    "#     roc_auc_dict = {}\n",
    "#     for i, label in enumerate(all_labels):\n",
    "#         fpr, tpr, _ = roc_curve(y_true[:, i], y_pred[:, i])\n",
    "#         roc_auc_dict[label] = auc(fpr, tpr)\n",
    "#         plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc_dict[label]:.2f})')\n",
    "    \n",
    "#     plt.title('Receiver Operating Characteristic')\n",
    "#     plt.legend(loc='lower right')\n",
    "#     plt.plot([0, 1], [0, 1], 'r--')\n",
    "#     plt.xlim([0, 1])\n",
    "#     plt.ylim([0, 1])\n",
    "#     plt.ylabel('True Positive Rate')\n",
    "#     plt.xlabel('False Positive Rate')\n",
    "#     plt.show()\n",
    "\n",
    "#     return roc_auc_dict\n",
    "\n",
    "# # Compute and plot ROC AUC\n",
    "# roc_auc_scores = compute_roc_auc(model, test_loader, len(all_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Function to compute the ROC AUC score\n",
    "def compute_roc_auc(model, data_loader, num_classes):\n",
    "    model.eval()\n",
    "    y_true = torch.FloatTensor().cuda()\n",
    "    y_pred = torch.FloatTensor().cuda()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in data_loader:\n",
    "            images, labels = images.cuda(), labels.cuda()\n",
    "            outputs = model(images)\n",
    "            y_true = torch.cat((y_true, labels), 0)\n",
    "            y_pred = torch.cat((y_pred, outputs), 0)\n",
    "\n",
    "    roc_auc_dict = {}\n",
    "    for i, label in enumerate(all_labels):\n",
    "        fpr, tpr, _ = roc_curve(y_true.cpu()[:, i], y_pred.cpu()[:, i])\n",
    "        roc_auc_dict[label] = auc(fpr, tpr)\n",
    "        plt.plot(fpr, tpr, label=f'{label} (AUC = {roc_auc_dict[label]:.2f})')\n",
    "    \n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.plot([0, 1], [0, 1], 'r--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1])\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.show()\n",
    "\n",
    "    return roc_auc_dict\n",
    "\n",
    "# Compute and plot ROC AUC\n",
    "roc_auc_scores = compute_roc_auc(model, test_loader, len(all_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(roc_auc_scores, flush = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Predictions\n",
    "def visualize_predictions(model, data_loader, num_images=4):\n",
    "    model.eval()\n",
    "    images, labels = next(iter(data_loader))\n",
    "    images, labels = images.cuda(), labels.cuda()\n",
    "    outputs = model(images)\n",
    "    outputs = outputs > 0.5  # Threshold predictions\n",
    "\n",
    "    fig, axs = plt.subplots(1, num_images, figsize=(15, 10))\n",
    "    for i in range(num_images):\n",
    "        axs[i].imshow(images[i].cpu().permute(1, 2, 0))\n",
    "        axs[i].axis('off')\n",
    "        disease_labels = ', '.join([all_labels[j] for j in range(outputs.shape[1]) if outputs[i, j] == 1])\n",
    "        axs[i].set_title(disease_labels)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Call visualization function\n",
    "visualize_predictions(model, test_loader, num_images=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
